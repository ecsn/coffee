{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import bipartite\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import operator\n",
    "from sknetwork.ranking import PageRank\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset (pre-processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle(r'datas/dataset_company_mapping_full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Attribute Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = nx.Graph() # create bipartite graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_graph(entity, dataset, graph):\n",
    "    schema = dataset[entity]\n",
    "    for eattribute in schema:\n",
    "        graph.add_nodes_from([entity], bipartite=0)\n",
    "        graph.add_nodes_from([eattribute], bipartite=1)\n",
    "        graph.add_edges_from([(entity, eattribute)])\n",
    "        \n",
    "        \n",
    "def buil_attribute_graph(graph):\n",
    "    top_nodes = {n for n, d in graph.nodes(data=True) if d['bipartite']==1}\n",
    "    bottom_nodes = set(graph) - top_nodes\n",
    "    parametro = list(top_nodes)\n",
    "    attribute_graph = bipartite.projected_graph(graph, parametro)\n",
    "    return attribute_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate bipartite graph\n",
    "for entity in dataset.keys():  \n",
    "    add_graph(entity, dataset, B)\n",
    "    \n",
    "attribute_graph = buil_attribute_graph(B) # create attribute graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_frequency(dataset):\n",
    "    frequency = {}\n",
    "    \n",
    "    attributes = []\n",
    "    entities = list(dataset.keys())\n",
    "\n",
    "    for entity in dataset.keys():\n",
    "        schema = dataset[entity]\n",
    "        for attribute in schema:\n",
    "            if attribute not in attributes:\n",
    "                attributes.append(attribute)\n",
    "\n",
    "    for a in attributes:\n",
    "        counter = 0\n",
    "        for e in entities:\n",
    "            if (a in dataset[e]):\n",
    "                counter+= 1\n",
    "        frequency[a] = counter/len(entities)\n",
    "    return frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrality = nx.degree_centrality(attribute_graph) # degree centrality\n",
    "closeness = nx.closeness_centrality(attribute_graph) # closeness centrality\n",
    "frequency = calculate_frequency(dataset) # frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Atributte relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance = {}\n",
    "\n",
    "for item in centrality.keys():\n",
    "    c = centrality[item]\n",
    "    p = closeness[item]\n",
    "    f = frequency[item]\n",
    "    relevance_item = (c*0.25)+(p*0.25)+(f*0.5)\n",
    "    relevance[item] = relevance_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Build the schema class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = list(dataset.keys())\n",
    "S = []\n",
    "\n",
    "for entity in E:\n",
    "    S.append(dataset[entity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65400/65400 [00:00<00:00, 1331867.73it/s]\n"
     ]
    }
   ],
   "source": [
    "sum_relevance = []\n",
    "sum_relevance_inverse = []\n",
    "for i in range(len(S)):\n",
    "    soma = 0\n",
    "    for att in S[i]:\n",
    "        soma += relevance[att]\n",
    "    sum_relevance.append(soma)\n",
    "    sum_relevance_inverse.append(1/soma)\n",
    "\n",
    "sum_rel = sum(sum_relevance)\n",
    "sum_rel_inv = sum(sum_relevance_inverse)\n",
    "\n",
    "\n",
    "alphas = []\n",
    "betas = []\n",
    "\n",
    "for i in tqdm(range(len(S))):\n",
    "    alpha = sum_relevance[i]/sum_rel\n",
    "    beta = (1/sum_relevance[i])/sum_rel_inv\n",
    "    alphas.append(alpha)\n",
    "    betas.append(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9999999999999395, 0.9999999999999803)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(alphas),sum(betas) # equal to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equation 2\n",
    "def quality_schema(Sc, schemas):\n",
    "    soma = 0\n",
    "    for j in range(len(schemas)):\n",
    "        a =  alphas[j] * (len(set(Sc).intersection(schemas[j]))/len(schemas[j])) # gain (equation 3) part 1 (equation 2)\n",
    "        b = betas[j] * (1 - len(set(Sc).intersection(schemas[j]))/len(Sc) )# cost (equation 3) part 2 (equation 2)\n",
    "        result = (a) - (b)\n",
    "        soma += result\n",
    "    return soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_attribute = sorted(relevance.items(), key=operator.itemgetter(1)) # tuple of attributes ordered by relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = [] # set of attributes ordered by relevance\n",
    "\n",
    "for element in order_attribute:\n",
    "    R.append(element[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  =  0.06\n",
      "2  =  0.11\n",
      "3  =  0.11\n",
      "4  =  0.11\n",
      "5  =  0.16\n",
      "6  =  0.17\n",
      "7  =  0.17\n",
      "8  =  0.18\n",
      "9  =  0.19\n",
      "10  =  0.17\n",
      "11  =  0.17\n",
      "12  =  0.17\n",
      "13  =  0.17\n",
      "14  =  0.17\n",
      "15  =  0.17\n",
      "16  =  0.17\n",
      "17  =  0.16\n",
      "18  =  0.17\n",
      "19  =  0.17\n",
      "20  =  0.17\n",
      "21  =  0.17\n",
      "22  =  0.16\n",
      "23  =  0.16\n",
      "24  =  0.16\n",
      "25  =  0.16\n",
      "26  =  0.16\n",
      "27  =  0.16\n",
      "28  =  0.16\n",
      "29  =  0.15\n",
      "30  =  0.15\n",
      "31  =  0.15\n",
      "32  =  0.15\n",
      "33  =  0.15\n",
      "34  =  0.15\n",
      "35  =  0.15\n",
      "36  =  0.15\n",
      "37  =  0.14\n",
      "38  =  0.14\n",
      "39  =  0.14\n",
      "40  =  0.14\n",
      "41  =  0.13\n",
      "42  =  0.13\n",
      "43  =  0.13\n",
      "44  =  0.13\n",
      "45  =  0.12\n",
      "46  =  0.12\n",
      "47  =  0.12\n",
      "48  =  0.12\n",
      "49  =  0.11\n",
      "50  =  0.11\n",
      "51  =  0.11\n",
      "52  =  0.11\n",
      "53  =  0.11\n",
      "54  =  0.1\n",
      "55  =  0.1\n",
      "56  =  0.1\n",
      "57  =  0.1\n",
      "58  =  0.1\n",
      "59  =  0.09\n",
      "60  =  0.09\n",
      "===================================\n",
      "top- 9  =  0.19\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "# select attributes to the schema class (algorithm 1)\n",
    "q_max = 0\n",
    "k = -1\n",
    "\n",
    "for j in range(1, len(R)+1):\n",
    "    Sc = R[-j:]\n",
    "    q = round(quality_schema(Sc, S), 2)\n",
    "    if (q >= q_max):\n",
    "        q_max = q\n",
    "        k = j\n",
    "    print(j, ' = ', q)\n",
    "    \n",
    "print('===================================')\n",
    "print(\"top-\", k, ' = ', q_max)\n",
    "print('===================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_schema = R[-k:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save result\n",
    "pickle.dump(class_schema, open('output/company_schema', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
